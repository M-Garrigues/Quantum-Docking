{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathieug/miniforge3/envs/pasqal/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-01-29 16:35:42,141\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-01-29 16:35:42,633\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pulser\n",
    "from matplotlib import pyplot as plt\n",
    "from networkx.algorithms import approximation\n",
    "import ray\n",
    "from ray import tune\n",
    "from src.solver.opt_vqaa import VQAA\n",
    "from src.solver.utils.graph_register import GraphRegister"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m      5\u001b[0m BASE_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/registers/dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# for file_path in os.listdir(\"./data/registers/tests\"):\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     path = os.path.join(BASE_PATH, file_path)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     print(path)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     VQAA(register_file=path, optimisation_rounds=20, store_results=True)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m data, labels \u001b[38;5;241m=\u001b[39m \u001b[43mpre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_PATH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/8_rectangle_4_2_10.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels)\n",
      "File \u001b[0;32m~/Projects/quantum/Quantum-Docking/notebooks/../src/solver/ml/dataset.py:93\u001b[0m, in \u001b[0;36mdata_from_file\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     91\u001b[0m qubits \u001b[38;5;241m=\u001b[39m register\u001b[38;5;241m.\u001b[39mqubits\n\u001b[1;32m     92\u001b[0m adjacency_matrix \u001b[38;5;241m=\u001b[39m create_adjacency_matrix(\u001b[38;5;28mlist\u001b[39m(qubits\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m---> 93\u001b[0m targets \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(\u001b[43mregister\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m adjacency_matrix, targets[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'params'"
     ]
    }
   ],
   "source": [
    "import src.solver.ml.dataset as pre\n",
    "\n",
    "import os\n",
    "\n",
    "BASE_PATH = \"../data/registers/dataset\"\n",
    "\n",
    "# for file_path in os.listdir(\"./data/registers/tests\"):\n",
    "#     path = os.path.join(BASE_PATH, file_path)\n",
    "#     print(path)\n",
    "#     VQAA(register_file=path, optimisation_rounds=20, store_results=True)\n",
    "\n",
    "\n",
    "data, labels = pre.data_from_file(BASE_PATH + \"/8_rectangle_4_2_10.json\")\n",
    "print(data)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1', 109.0), ('1', 1899.0), ('1', 457.0), ('1', 570.0), ('1', 398.0), ('6', 2098.0), ('8', 1546.0), ('7', 1767.0), ('8', 2447.0), ('8', 2433.0), ('6', 1952.0), ('1', 358.0), ('6', 2127.0), ('1', 1525.0), ('6', 1856.0), ('6', 1836.0), ('8', 2242.0), ('6', 2333.0), ('8', 1926.0), ('9', 1115.0), ('7', 818.0), ('c', 2175.0), ('t', 657.0), ('1', 1325.0), ('9', 2489.0), ('9', 2392.0), ('1', 436.0), ('1', 1430.0), ('s', 2020.0), ('8', 1791.0), ('8', 1533.0), ('1', 362.0), ('6', 1954.0), ('9', 2238.0), ('8', 2443.0), ('7', 1986.0), ('9', 2229.0), ('7', 1399.0), ('1', 2489.0), ('7', 1084.0), ('7', 1402.0), ('1', 2393.0), ('7', 2386.0), ('9', 1850.0), ('9', 2305.0), ('9', 1025.0), ('6', 2475.0), ('7', 1777.0), ('1', 2086.0), ('1', 236.0), ('1', 1927.0), ('1', 273.0), ('1', 2204.0), ('1', 1166.0), ('c', 561.0), ('8', 956.0), ('6', 1891.0), ('8', 1450.0), ('7', 1274.0), ('7', 1749.0), ('1', 344.0), ('8', 2157.0), ('8', 1398.0), ('1', 580.0), ('6', 1320.0), ('1', 1657.0), ('1', 613.0), ('1', 2197.0), ('1', 409.0), ('6', 1517.0), ('9', 2277.0), ('8', 2367.0), ('7', 747.0), ('6', 1160.0), ('6', 1928.0), ('1', 1174.0), ('1', 1305.0), ('8', 283.0), ('6', 2481.0), ('7', 2102.0), ('8', 1992.0), ('1', 597.0), ('9', 653.0), ('1', 2424.0), ('6', 1828.0), ('9', 1134.0), ('7', 1586.0), ('1', 384.0), ('1', 446.0), ('7', 476.0), ('7', 1835.0), ('6', 2078.0), ('9', 2475.0), ('8', 2414.0), ('s', 1795.0), ('7', 1814.0), ('1', 468.0), ('1', 338.0), ('1', 389.0), ('1', 521.0), ('1', 1881.0), ('7', 1900.0), ('9', 1251.0), ('1', 1385.0), ('9', 2028.0), ('6', 1624.0), ('6', 2248.0), ('9', 561.0), ('9', 2195.0), ('7', 1335.0), ('1', 1806.0), ('9', 1368.0), ('6', 1187.0), ('6', 2089.0), ('8', 2490.0), ('8', 2162.0), ('8', 1643.0), ('9', 1591.0), ('6', 2333.0), ('1', 2080.0), ('m', 464.0), ('7', 2388.0), ('1', 407.0), ('1', 377.0), ('8', 950.0), ('1', 345.0), ('e', 2373.0), ('8', 1804.0), ('1', 246.0), ('6', 1450.0), ('m', 1579.0), ('6', 1112.0), ('9', 1121.0), ('6', 2255.0), ('9', 2243.0), ('8', 2067.0), ('6', 2051.0), ('c', 527.0), ('9', 2239.0), ('7', 138.0), ('8', 1956.0), ('7', 626.0), ('8', 2485.0), ('7', 1882.0), ('7', 2199.0), ('9', 1121.0), ('1', 506.0), ('1', 1008.0), ('1', 1952.0), ('9', 2014.0), ('1', 1234.0), ('6', 2323.0), ('7', 1333.0), ('1', 367.0), ('8', 1625.0), ('9', 1073.0), ('9', 488.0), ('7', 1807.0), ('9', 1079.0), ('7', 2264.0), ('8', 1484.0), ('1', 231.0), ('7', 2084.0), ('7', 1681.0), ('1', 1102.0), ('1', 1150.0), ('9', 2093.0), ('7', 1743.0), ('6', 2403.0), ('1', 138.0), ('1', 218.0), ('8', 2081.0), ('6', 1235.0), ('8', 2341.0), ('8', 547.0), ('8', 865.0), ('8', 1767.0), ('1', 1884.0), ('1', 1438.0), ('6', 2443.0), ('6', 1541.0), ('9', 551.0), ('6', 1220.0), ('8', 967.0), ('1', 489.0), ('m', 2306.0), ('1', 535.0), ('9', 1728.0), ('8', 593.0), ('7', 892.0), ('7', 564.0), ('7', 1301.0), ('1', 578.0), ('9', 1115.0), ('1', 521.0), ('9', 2469.0), ('9', 1815.0), ('9', 1517.0), ('7', 1286.0), ('9', 973.0), ('s', 1457.0), ('1', 1020.0), ('6', 1444.0), ('7', 2203.0), ('1', 550.0), ('c', 201.0), ('8', 1268.0), ('1', 252.0), ('6', 1335.0), ('6', 1356.0), ('1', 276.0), ('1', 413.0)]\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "\n",
    "for path in os.listdir(BASE_PATH):\n",
    "    try:\n",
    "        data, target = pre.data_from_file(os.path.join(BASE_PATH, path))\n",
    "        nb_nodes = len(data)\n",
    "        ls.append((nb_nodes, target))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "distance_list = []\n",
    "\n",
    "for path in os.listdir(BASE_PATH):\n",
    "    try:\n",
    "        data, target = pre.data_from_file(os.path.join(BASE_PATH, path))\n",
    "        spl = path.split(\"_\")\n",
    "        distance = spl[-1][0]\n",
    "        distance_list.append((distance, target))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(distance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 3: 1155.3333333333333,\n",
      "  4: 1580.5925925925926,\n",
      "  5: 1458.25,\n",
      "  6: 1353.4772727272727,\n",
      "  7: 1319.45,\n",
      "  8: 1435.6785714285713,\n",
      "  9: 1531.8,\n",
      "  10: 1424.5416666666667,\n",
      "  11: 1701.7,\n",
      "  12: 1744.75}\n",
      "{ '1': 935.59375,\n",
      "  '6': 1837.735294117647,\n",
      "  '7': 1524.3529411764705,\n",
      "  '8': 1719.7941176470588,\n",
      "  '9': 1612.2058823529412,\n",
      "  'c': 866.0,\n",
      "  'e': 2373.0,\n",
      "  'm': 1449.6666666666667,\n",
      "  's': 1757.3333333333333,\n",
      "  't': 657.0}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def calculate_average_by_index(data):\n",
    "    index_sum = {}\n",
    "    index_count = {}\n",
    "\n",
    "    for index, value in data:\n",
    "        if index in index_sum:\n",
    "            index_sum[index] += value\n",
    "            index_count[index] += 1\n",
    "        else:\n",
    "            index_sum[index] = value\n",
    "            index_count[index] = 1\n",
    "\n",
    "    averages = {index: index_sum[index] / index_count[index] for index in index_sum}\n",
    "\n",
    "    return averages\n",
    "\n",
    "\n",
    "result = calculate_average_by_index(ls)\n",
    "result = dict(sorted(result.items()))\n",
    "pprint(result, indent=2)\n",
    "\n",
    "distance_impact = calculate_average_by_index(distance_list)\n",
    "distance_impact = dict(sorted(distance_impact.items()))\n",
    "pprint(distance_impact, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: CustomGraphDataset(169):\n",
      "====================\n",
      "Number of graphs: 169\n",
      "Number of features: 0 \n",
      "Number of classes: 162\n",
      "Data(edge_index=[2, 60], y=[1], edge_weight=[60], num_nodes=6)\n",
      "=============================================================\n",
      "Number of nodes: 6\n",
      "Number of edges: 60\n",
      "Average node degree: 10.00\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "from src.solver.ml.dataset import CustomGraphDataset\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "folder_path = BASE_PATH\n",
    "\n",
    "dataset = CustomGraphDataset(folder_path).shuffle()\n",
    "train_ds = dataset[:70]\n",
    "test_ds = dataset[70:]\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# custom_dataset.get(0)\n",
    "\n",
    "print()\n",
    "print(f\"Dataset: {dataset}:\")\n",
    "print(\"====================\")\n",
    "print(f\"Number of graphs: {len(dataset)}\")\n",
    "print(f\"Number of features: {dataset.num_features} \")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print(data)\n",
    "print(\"=============================================================\")\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f\"Number of nodes: {data.num_nodes}\")\n",
    "print(f\"Number of edges: {data.num_edges}\")\n",
    "print(f\"Average node degree: {data.num_edges / data.num_nodes:.2f}\")\n",
    "print(f\"Has isolated nodes: {data.has_isolated_nodes()}\")\n",
    "print(f\"Has self-loops: {data.has_self_loops()}\")\n",
    "print(f\"Is undirected: {data.is_undirected()}\")\n",
    "print(data.num_edge_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 2916], y=[32], edge_weight=[2916], num_nodes=212, batch=[212], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3240], y=[32], edge_weight=[3240], num_nodes=232, batch=[232], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 2704], y=[32], edge_weight=[2704], num_nodes=215, batch=[215], ptr=[33])\n",
      "32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 2880], y=[32], edge_weight=[2880], num_nodes=220, batch=[220], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3448], y=[32], edge_weight=[3448], num_nodes=238, batch=[238], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 696], y=[9], edge_weight=[696], num_nodes=58, batch=[58], ptr=[10])\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    print(batch)\n",
    "    print(batch.num_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    model.train()\n",
    "\n",
    "    for data in loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y.view(len(data.y), 1))  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    tot = 0\n",
    "    size = 0\n",
    "\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        # print(data)\n",
    "        out = model(data)\n",
    "        tot += sum(abs((out - data.y.view(len(data.y), 1))))\n",
    "        size += data.num_graphs\n",
    "\n",
    "    # print(out)\n",
    "    return tot / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 8\n",
      "Number of edges: 112\n",
      "Average node degree: 14.00\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "Epoch: 010, Train Acc: 3.087188959121704, Test Acc: 2.2663\n",
      "Epoch: 020, Train Acc: 2.0898609161376953, Test Acc: 1.5373\n",
      "Epoch: 030, Train Acc: 1.970997929573059, Test Acc: 1.8244\n",
      "Epoch: 040, Train Acc: 1.957754373550415, Test Acc: 1.9259\n",
      "Epoch: 050, Train Acc: 1.959067940711975, Test Acc: 1.9365\n",
      "Epoch: 060, Train Acc: 1.950383186340332, Test Acc: 1.8983\n",
      "Epoch: 070, Train Acc: 1.942442536354065, Test Acc: 1.9003\n",
      "Epoch: 080, Train Acc: 1.933681607246399, Test Acc: 1.9070\n",
      "Epoch: 090, Train Acc: 1.9171388149261475, Test Acc: 1.8934\n",
      "Epoch: 100, Train Acc: 1.8901914358139038, Test Acc: 1.9031\n",
      "Epoch: 110, Train Acc: 1.8604469299316406, Test Acc: 1.9236\n",
      "Epoch: 120, Train Acc: 1.827800989151001, Test Acc: 1.9079\n",
      "Epoch: 130, Train Acc: 1.8556480407714844, Test Acc: 1.9478\n",
      "Epoch: 140, Train Acc: 1.811936855316162, Test Acc: 1.9267\n",
      "Epoch: 150, Train Acc: 1.8008583784103394, Test Acc: 1.8914\n",
      "Epoch: 160, Train Acc: 1.7932533025741577, Test Acc: 1.8903\n",
      "Epoch: 170, Train Acc: 1.803512692451477, Test Acc: 1.8907\n",
      "Epoch: 180, Train Acc: 1.7927618026733398, Test Acc: 1.8786\n",
      "Epoch: 190, Train Acc: 1.7911323308944702, Test Acc: 1.8529\n",
      "Epoch: 200, Train Acc: 1.784371018409729, Test Acc: 1.8766\n",
      "Epoch: 210, Train Acc: 1.7891366481781006, Test Acc: 1.8930\n",
      "Epoch: 220, Train Acc: 1.7847380638122559, Test Acc: 1.8865\n",
      "Epoch: 230, Train Acc: 1.784855842590332, Test Acc: 1.8747\n",
      "Epoch: 240, Train Acc: 1.787804126739502, Test Acc: 1.8598\n",
      "Epoch: 250, Train Acc: 1.782244086265564, Test Acc: 1.8567\n",
      "Epoch: 260, Train Acc: 1.7878016233444214, Test Acc: 1.8790\n",
      "Epoch: 270, Train Acc: 1.7795896530151367, Test Acc: 1.8692\n",
      "Epoch: 280, Train Acc: 1.777368426322937, Test Acc: 1.8701\n",
      "Epoch: 290, Train Acc: 1.7861638069152832, Test Acc: 1.8796\n",
      "Epoch: 300, Train Acc: 1.7834863662719727, Test Acc: 1.8665\n",
      "Epoch: 310, Train Acc: 1.783237338066101, Test Acc: 1.8486\n",
      "Epoch: 320, Train Acc: 1.7851533889770508, Test Acc: 1.8595\n",
      "Epoch: 330, Train Acc: 1.782295823097229, Test Acc: 1.8927\n",
      "Epoch: 340, Train Acc: 1.7803703546524048, Test Acc: 1.8825\n",
      "Epoch: 350, Train Acc: 1.787732720375061, Test Acc: 1.8495\n",
      "Epoch: 360, Train Acc: 1.7789521217346191, Test Acc: 1.8603\n",
      "Epoch: 370, Train Acc: 1.7949885129928589, Test Acc: 1.9033\n",
      "Epoch: 380, Train Acc: 1.7805211544036865, Test Acc: 1.8826\n",
      "Epoch: 390, Train Acc: 1.7826772928237915, Test Acc: 1.8862\n",
      "Epoch: 400, Train Acc: 1.783443570137024, Test Acc: 1.8574\n",
      "Epoch: 410, Train Acc: 1.7796381711959839, Test Acc: 1.8709\n",
      "Epoch: 420, Train Acc: 1.7793152332305908, Test Acc: 1.8784\n",
      "Epoch: 430, Train Acc: 1.780269980430603, Test Acc: 1.8852\n",
      "Epoch: 440, Train Acc: 1.780400037765503, Test Acc: 1.8877\n",
      "Epoch: 450, Train Acc: 1.7773374319076538, Test Acc: 1.8824\n",
      "Epoch: 460, Train Acc: 1.78523588180542, Test Acc: 1.9044\n",
      "Epoch: 470, Train Acc: 1.784688115119934, Test Acc: 1.8752\n",
      "Epoch: 480, Train Acc: 1.772780418395996, Test Acc: 1.8794\n",
      "Epoch: 490, Train Acc: 1.779577612876892, Test Acc: 1.8717\n",
      "Epoch: 500, Train Acc: 1.7773771286010742, Test Acc: 1.8746\n",
      "Epoch: 510, Train Acc: 1.779287338256836, Test Acc: 1.8762\n",
      "Epoch: 520, Train Acc: 1.7797561883926392, Test Acc: 1.8652\n",
      "Epoch: 530, Train Acc: 1.7798328399658203, Test Acc: 1.8859\n",
      "Epoch: 540, Train Acc: 1.7801259756088257, Test Acc: 1.8648\n",
      "Epoch: 550, Train Acc: 1.7760722637176514, Test Acc: 1.8829\n",
      "Epoch: 560, Train Acc: 1.77805757522583, Test Acc: 1.8623\n",
      "Epoch: 570, Train Acc: 1.7785390615463257, Test Acc: 1.8739\n",
      "Epoch: 580, Train Acc: 1.784827470779419, Test Acc: 1.8974\n",
      "Epoch: 590, Train Acc: 1.781743049621582, Test Acc: 1.9022\n",
      "Epoch: 600, Train Acc: 1.7809782028198242, Test Acc: 1.8794\n",
      "Epoch: 610, Train Acc: 1.7763727903366089, Test Acc: 1.9020\n",
      "Epoch: 620, Train Acc: 1.7806733846664429, Test Acc: 1.8883\n",
      "Epoch: 630, Train Acc: 1.781693458557129, Test Acc: 1.8643\n",
      "Epoch: 640, Train Acc: 1.788023829460144, Test Acc: 1.9037\n",
      "Epoch: 650, Train Acc: 1.779114842414856, Test Acc: 1.8561\n",
      "Epoch: 660, Train Acc: 1.78486967086792, Test Acc: 1.8631\n",
      "Epoch: 670, Train Acc: 1.780840516090393, Test Acc: 1.8793\n",
      "Epoch: 680, Train Acc: 1.780622959136963, Test Acc: 1.8896\n",
      "Epoch: 690, Train Acc: 1.7764604091644287, Test Acc: 1.8726\n",
      "Epoch: 700, Train Acc: 1.778672695159912, Test Acc: 1.8658\n",
      "Epoch: 710, Train Acc: 1.7760930061340332, Test Acc: 1.8747\n",
      "Epoch: 720, Train Acc: 1.7798079252243042, Test Acc: 1.8601\n",
      "Epoch: 730, Train Acc: 1.778119683265686, Test Acc: 1.8834\n",
      "Epoch: 740, Train Acc: 1.7827904224395752, Test Acc: 1.8736\n",
      "Epoch: 750, Train Acc: 1.7891978025436401, Test Acc: 1.9114\n",
      "Epoch: 760, Train Acc: 1.7826282978057861, Test Acc: 1.9252\n",
      "Epoch: 770, Train Acc: 1.777930498123169, Test Acc: 1.8790\n",
      "Epoch: 780, Train Acc: 1.7728462219238281, Test Acc: 1.9008\n",
      "Epoch: 790, Train Acc: 1.7774173021316528, Test Acc: 1.8699\n",
      "Epoch: 800, Train Acc: 1.7718507051467896, Test Acc: 1.8808\n",
      "Epoch: 810, Train Acc: 1.773524284362793, Test Acc: 1.8590\n",
      "Epoch: 820, Train Acc: 1.7762693166732788, Test Acc: 1.8640\n",
      "Epoch: 830, Train Acc: 1.773686170578003, Test Acc: 1.8845\n",
      "Epoch: 840, Train Acc: 1.7784028053283691, Test Acc: 1.8619\n",
      "Epoch: 850, Train Acc: 1.7833172082901, Test Acc: 1.8539\n",
      "Epoch: 860, Train Acc: 1.7766591310501099, Test Acc: 1.8588\n",
      "Epoch: 870, Train Acc: 1.783433198928833, Test Acc: 1.8774\n",
      "Epoch: 880, Train Acc: 1.7772883176803589, Test Acc: 1.8650\n",
      "Epoch: 890, Train Acc: 1.7756469249725342, Test Acc: 1.8783\n",
      "Epoch: 900, Train Acc: 1.7813643217086792, Test Acc: 1.8291\n",
      "Epoch: 910, Train Acc: 1.7831861972808838, Test Acc: 1.8960\n",
      "Epoch: 920, Train Acc: 1.775413990020752, Test Acc: 1.9014\n",
      "Epoch: 930, Train Acc: 1.7740367650985718, Test Acc: 1.8727\n",
      "Epoch: 940, Train Acc: 1.7715955972671509, Test Acc: 1.8876\n",
      "Epoch: 950, Train Acc: 1.7759512662887573, Test Acc: 1.8795\n",
      "Epoch: 960, Train Acc: 1.773113489151001, Test Acc: 1.8740\n",
      "Epoch: 970, Train Acc: 1.770973563194275, Test Acc: 1.8834\n",
      "Epoch: 980, Train Acc: 1.774045467376709, Test Acc: 1.8829\n",
      "Epoch: 990, Train Acc: 1.7805836200714111, Test Acc: 1.8756\n",
      "Epoch: 1000, Train Acc: 1.7790266275405884, Test Acc: 1.8776\n",
      "Epoch: 1010, Train Acc: 1.7750990390777588, Test Acc: 1.8842\n",
      "Epoch: 1020, Train Acc: 1.7882064580917358, Test Acc: 1.8590\n",
      "Epoch: 1030, Train Acc: 1.7763018608093262, Test Acc: 1.8778\n",
      "Epoch: 1040, Train Acc: 1.7789301872253418, Test Acc: 1.8679\n",
      "Epoch: 1050, Train Acc: 1.775281310081482, Test Acc: 1.9021\n",
      "Epoch: 1060, Train Acc: 1.7736576795578003, Test Acc: 1.8780\n",
      "Epoch: 1070, Train Acc: 1.775011420249939, Test Acc: 1.8839\n",
      "Epoch: 1080, Train Acc: 1.7793006896972656, Test Acc: 1.8765\n",
      "Epoch: 1090, Train Acc: 1.7709850072860718, Test Acc: 1.8749\n",
      "Epoch: 1100, Train Acc: 1.7738533020019531, Test Acc: 1.8900\n",
      "Epoch: 1110, Train Acc: 1.7771544456481934, Test Acc: 1.8987\n",
      "Epoch: 1120, Train Acc: 1.796534776687622, Test Acc: 1.9146\n",
      "Epoch: 1130, Train Acc: 1.781779170036316, Test Acc: 1.8953\n",
      "Epoch: 1140, Train Acc: 1.771875023841858, Test Acc: 1.8925\n",
      "Epoch: 1150, Train Acc: 1.7772616147994995, Test Acc: 1.8750\n",
      "Epoch: 1160, Train Acc: 1.772952675819397, Test Acc: 1.8902\n",
      "Epoch: 1170, Train Acc: 1.7833795547485352, Test Acc: 1.8773\n",
      "Epoch: 1180, Train Acc: 1.7728328704833984, Test Acc: 1.8811\n",
      "Epoch: 1190, Train Acc: 1.778071403503418, Test Acc: 1.9064\n",
      "Epoch: 1200, Train Acc: 1.7781333923339844, Test Acc: 1.8594\n",
      "Epoch: 1210, Train Acc: 1.774031400680542, Test Acc: 1.8818\n",
      "Epoch: 1220, Train Acc: 1.7827352285385132, Test Acc: 1.8701\n",
      "Epoch: 1230, Train Acc: 1.7662022113800049, Test Acc: 1.8788\n",
      "Epoch: 1240, Train Acc: 1.77265465259552, Test Acc: 1.8809\n",
      "Epoch: 1250, Train Acc: 1.7736072540283203, Test Acc: 1.8845\n",
      "Epoch: 1260, Train Acc: 1.7724109888076782, Test Acc: 1.8952\n",
      "Epoch: 1270, Train Acc: 1.772274374961853, Test Acc: 1.8577\n",
      "Epoch: 1280, Train Acc: 1.7700974941253662, Test Acc: 1.9101\n",
      "Epoch: 1290, Train Acc: 1.777016520500183, Test Acc: 1.8660\n",
      "Epoch: 1300, Train Acc: 1.7767047882080078, Test Acc: 1.8546\n",
      "Epoch: 1310, Train Acc: 1.773583173751831, Test Acc: 1.8988\n",
      "Epoch: 1320, Train Acc: 1.7695223093032837, Test Acc: 1.8588\n",
      "Epoch: 1330, Train Acc: 1.7749083042144775, Test Acc: 1.8800\n",
      "Epoch: 1340, Train Acc: 1.7738902568817139, Test Acc: 1.8880\n",
      "Epoch: 1350, Train Acc: 1.7744543552398682, Test Acc: 1.8666\n",
      "Epoch: 1360, Train Acc: 1.7796299457550049, Test Acc: 1.8652\n",
      "Epoch: 1370, Train Acc: 1.773045539855957, Test Acc: 1.8900\n",
      "Epoch: 1380, Train Acc: 1.76806640625, Test Acc: 1.8709\n",
      "Epoch: 1390, Train Acc: 1.7760241031646729, Test Acc: 1.8659\n",
      "Epoch: 1400, Train Acc: 1.7711800336837769, Test Acc: 1.8836\n",
      "Epoch: 1410, Train Acc: 1.7732588052749634, Test Acc: 1.8904\n",
      "Epoch: 1420, Train Acc: 1.7763639688491821, Test Acc: 1.8755\n",
      "Epoch: 1430, Train Acc: 1.7674150466918945, Test Acc: 1.8975\n",
      "Epoch: 1440, Train Acc: 1.766398549079895, Test Acc: 1.9173\n",
      "Epoch: 1450, Train Acc: 1.772497296333313, Test Acc: 1.8742\n",
      "Epoch: 1460, Train Acc: 1.7729672193527222, Test Acc: 1.8918\n",
      "Epoch: 1470, Train Acc: 1.7827715873718262, Test Acc: 1.8835\n",
      "Epoch: 1480, Train Acc: 1.7674022912979126, Test Acc: 1.8760\n",
      "Epoch: 1490, Train Acc: 1.7690149545669556, Test Acc: 1.8826\n",
      "Epoch: 1500, Train Acc: 1.7692323923110962, Test Acc: 1.8645\n",
      "Epoch: 1510, Train Acc: 1.7698825597763062, Test Acc: 1.8958\n",
      "Epoch: 1520, Train Acc: 1.7661786079406738, Test Acc: 1.8895\n",
      "Epoch: 1530, Train Acc: 1.7742060422897339, Test Acc: 1.8653\n",
      "Epoch: 1540, Train Acc: 1.768596887588501, Test Acc: 1.8838\n",
      "Epoch: 1550, Train Acc: 1.764940619468689, Test Acc: 1.8840\n",
      "Epoch: 1560, Train Acc: 1.7703596353530884, Test Acc: 1.8810\n",
      "Epoch: 1570, Train Acc: 1.7686583995819092, Test Acc: 1.8649\n",
      "Epoch: 1580, Train Acc: 1.7785401344299316, Test Acc: 1.8555\n",
      "Epoch: 1590, Train Acc: 1.7624163627624512, Test Acc: 1.8706\n",
      "Epoch: 1600, Train Acc: 1.772833228111267, Test Acc: 1.8570\n",
      "Epoch: 1610, Train Acc: 1.7787394523620605, Test Acc: 1.8565\n",
      "Epoch: 1620, Train Acc: 1.763288974761963, Test Acc: 1.8809\n",
      "Epoch: 1630, Train Acc: 1.765863299369812, Test Acc: 1.8629\n",
      "Epoch: 1640, Train Acc: 1.77806556224823, Test Acc: 1.8644\n",
      "Epoch: 1650, Train Acc: 1.769425630569458, Test Acc: 1.9047\n",
      "Epoch: 1660, Train Acc: 1.7790793180465698, Test Acc: 1.8458\n",
      "Epoch: 1670, Train Acc: 1.7630133628845215, Test Acc: 1.8442\n",
      "Epoch: 1680, Train Acc: 1.7736867666244507, Test Acc: 1.8480\n",
      "Epoch: 1690, Train Acc: 1.7672419548034668, Test Acc: 1.8655\n",
      "Epoch: 1700, Train Acc: 1.762082576751709, Test Acc: 1.8958\n",
      "Epoch: 1710, Train Acc: 1.778800368309021, Test Acc: 1.8493\n",
      "Epoch: 1720, Train Acc: 1.771243691444397, Test Acc: 1.8616\n",
      "Epoch: 1730, Train Acc: 1.777722716331482, Test Acc: 1.8753\n",
      "Epoch: 1740, Train Acc: 1.769877552986145, Test Acc: 1.9065\n",
      "Epoch: 1750, Train Acc: 1.7719166278839111, Test Acc: 1.8414\n",
      "Epoch: 1760, Train Acc: 1.7699682712554932, Test Acc: 1.8842\n",
      "Epoch: 1770, Train Acc: 1.771636724472046, Test Acc: 1.8452\n",
      "Epoch: 1780, Train Acc: 1.7759582996368408, Test Acc: 1.8905\n",
      "Epoch: 1790, Train Acc: 1.7623274326324463, Test Acc: 1.8616\n",
      "Epoch: 1800, Train Acc: 1.786908745765686, Test Acc: 1.8480\n",
      "Epoch: 1810, Train Acc: 1.7637929916381836, Test Acc: 1.8795\n",
      "Epoch: 1820, Train Acc: 1.7742372751235962, Test Acc: 1.8597\n",
      "Epoch: 1830, Train Acc: 1.7679681777954102, Test Acc: 1.8582\n",
      "Epoch: 1840, Train Acc: 1.773017406463623, Test Acc: 1.9215\n",
      "Epoch: 1850, Train Acc: 1.754360318183899, Test Acc: 1.8875\n",
      "Epoch: 1860, Train Acc: 1.765599012374878, Test Acc: 1.8852\n",
      "Epoch: 1870, Train Acc: 1.7663898468017578, Test Acc: 1.8858\n",
      "Epoch: 1880, Train Acc: 1.7554717063903809, Test Acc: 1.9209\n",
      "Epoch: 1890, Train Acc: 1.756832242012024, Test Acc: 1.9289\n",
      "Epoch: 1900, Train Acc: 1.772128939628601, Test Acc: 1.9096\n",
      "Epoch: 1910, Train Acc: 1.758920669555664, Test Acc: 1.8839\n",
      "Epoch: 1920, Train Acc: 1.762585163116455, Test Acc: 1.8924\n",
      "Epoch: 1930, Train Acc: 1.7688877582550049, Test Acc: 1.8932\n",
      "Epoch: 1940, Train Acc: 1.7604002952575684, Test Acc: 1.8676\n",
      "Epoch: 1950, Train Acc: 1.7717444896697998, Test Acc: 1.8427\n",
      "Epoch: 1960, Train Acc: 1.7456547021865845, Test Acc: 1.8820\n",
      "Epoch: 1970, Train Acc: 1.7681406736373901, Test Acc: 1.8887\n",
      "Epoch: 1980, Train Acc: 1.7587604522705078, Test Acc: 1.8696\n",
      "Epoch: 1990, Train Acc: 1.7583867311477661, Test Acc: 1.8830\n"
     ]
    }
   ],
   "source": [
    "from src.solver.ml.model import GraphRegressionModel\n",
    "import torch\n",
    "from torchmetrics.regression import MeanAbsoluteError\n",
    "from src.solver.ml.dataset import CustomGraphDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "\n",
    "def RMSELoss(yhat, y):\n",
    "    return torch.sqrt(torch.mean((yhat - y) ** 2))\n",
    "\n",
    "\n",
    "criterion = RMSELoss\n",
    "\n",
    "\n",
    "input_dim = 1\n",
    "hidden_dim = 128\n",
    "output_dim = 1  # Regression output\n",
    "batch_size = 64\n",
    "folder_path = \"../data/registers/results/results_500_samples\"\n",
    "\n",
    "model = GraphRegressionModel(hidden_dim)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "dataset = CustomGraphDataset(folder_path, target_index=3).shuffle()\n",
    "train_ds = dataset[:115]\n",
    "test_ds = dataset[115:]\n",
    "\n",
    "# print(f\"Number of training graphs: {len(train_ds)}\")\n",
    "# print(f\"Number of test graphs: {len(test_ds)}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "data = train_ds[0]\n",
    "\n",
    "print(f\"Number of nodes: {data.num_nodes}\")\n",
    "print(f\"Number of edges: {data.num_edges}\")\n",
    "print(f\"Average node degree: {data.num_edges / data.num_nodes:.2f}\")\n",
    "print(f\"Has isolated nodes: {data.has_isolated_nodes()}\")\n",
    "print(f\"Has self-loops: {data.has_self_loops()}\")\n",
    "print(f\"Is undirected: {data.is_undirected()}\")\n",
    "\n",
    "\n",
    "for epoch in range(1, 2000):\n",
    "    train(train_loader)\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch:03d}, Train Acc: {train_acc.item()}, Test Acc: {test_acc.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Acc: 3.0116446018218994\n",
      "Epoch: 020, Train Acc: 2.085949659347534\n",
      "Epoch: 030, Train Acc: 1.9735212326049805\n",
      "Epoch: 040, Train Acc: 1.9551862478256226\n",
      "Epoch: 050, Train Acc: 1.929052472114563\n",
      "Epoch: 060, Train Acc: 1.891137719154358\n",
      "Epoch: 070, Train Acc: 1.8615117073059082\n",
      "Epoch: 080, Train Acc: 1.846835970878601\n",
      "Epoch: 090, Train Acc: 1.8389668464660645\n",
      "Epoch: 100, Train Acc: 1.833407998085022\n",
      "Epoch: 110, Train Acc: 1.8341495990753174\n",
      "Epoch: 120, Train Acc: 1.8311213254928589\n",
      "Epoch: 130, Train Acc: 1.82429838180542\n",
      "Epoch: 140, Train Acc: 1.8235973119735718\n",
      "Epoch: 150, Train Acc: 1.8301161527633667\n",
      "Epoch: 160, Train Acc: 1.8284990787506104\n",
      "Epoch: 170, Train Acc: 1.8214021921157837\n",
      "Epoch: 180, Train Acc: 1.8255527019500732\n",
      "Epoch: 190, Train Acc: 1.820212483406067\n",
      "Epoch: 200, Train Acc: 1.8199275732040405\n",
      "Epoch: 210, Train Acc: 1.8179852962493896\n",
      "Epoch: 220, Train Acc: 1.82954740524292\n",
      "Epoch: 230, Train Acc: 1.81611967086792\n",
      "Epoch: 240, Train Acc: 1.8224653005599976\n",
      "Epoch: 250, Train Acc: 1.8174465894699097\n",
      "Epoch: 260, Train Acc: 1.8209689855575562\n",
      "Epoch: 270, Train Acc: 1.8223849534988403\n",
      "Epoch: 280, Train Acc: 1.8168213367462158\n",
      "Epoch: 290, Train Acc: 1.8223508596420288\n",
      "Epoch: 300, Train Acc: 1.820336937904358\n",
      "Epoch: 310, Train Acc: 1.8175936937332153\n",
      "Epoch: 320, Train Acc: 1.8125919103622437\n",
      "Epoch: 330, Train Acc: 1.8190442323684692\n",
      "Epoch: 340, Train Acc: 1.812514305114746\n",
      "Epoch: 350, Train Acc: 1.8125627040863037\n",
      "Epoch: 360, Train Acc: 1.8124678134918213\n",
      "Epoch: 370, Train Acc: 1.8140231370925903\n",
      "Epoch: 380, Train Acc: 1.8080662488937378\n",
      "Epoch: 390, Train Acc: 1.8115637302398682\n",
      "Epoch: 400, Train Acc: 1.811550259590149\n",
      "Epoch: 410, Train Acc: 1.8143593072891235\n",
      "Epoch: 420, Train Acc: 1.8064565658569336\n",
      "Epoch: 430, Train Acc: 1.8056362867355347\n",
      "Epoch: 440, Train Acc: 1.8132200241088867\n",
      "Epoch: 450, Train Acc: 1.8056496381759644\n",
      "Epoch: 460, Train Acc: 1.8007415533065796\n",
      "Epoch: 470, Train Acc: 1.8091028928756714\n",
      "Epoch: 480, Train Acc: 1.8015851974487305\n",
      "Epoch: 490, Train Acc: 1.8054946660995483\n",
      "Epoch: 500, Train Acc: 1.8097025156021118\n",
      "Epoch: 510, Train Acc: 1.7983617782592773\n",
      "Epoch: 520, Train Acc: 1.8046140670776367\n",
      "Epoch: 530, Train Acc: 1.8063650131225586\n",
      "Epoch: 540, Train Acc: 1.8050696849822998\n",
      "Epoch: 550, Train Acc: 1.8012782335281372\n",
      "Epoch: 560, Train Acc: 1.8057129383087158\n",
      "Epoch: 570, Train Acc: 1.7971347570419312\n",
      "Epoch: 580, Train Acc: 1.8025214672088623\n",
      "Epoch: 590, Train Acc: 1.80423104763031\n",
      "Epoch: 600, Train Acc: 1.8066422939300537\n",
      "Epoch: 610, Train Acc: 1.8044939041137695\n",
      "Epoch: 620, Train Acc: 1.8022241592407227\n",
      "Epoch: 630, Train Acc: 1.8043962717056274\n",
      "Epoch: 640, Train Acc: 1.8016999959945679\n",
      "Epoch: 650, Train Acc: 1.7970279455184937\n",
      "Epoch: 660, Train Acc: 1.8033154010772705\n",
      "Epoch: 670, Train Acc: 1.7981704473495483\n",
      "Epoch: 680, Train Acc: 1.79966402053833\n",
      "Epoch: 690, Train Acc: 1.8003337383270264\n",
      "Epoch: 700, Train Acc: 1.8066484928131104\n",
      "Epoch: 710, Train Acc: 1.8001450300216675\n",
      "Epoch: 720, Train Acc: 1.8028537034988403\n",
      "Epoch: 730, Train Acc: 1.793531894683838\n",
      "Epoch: 740, Train Acc: 1.7984896898269653\n",
      "Epoch: 750, Train Acc: 1.8022927045822144\n",
      "Epoch: 760, Train Acc: 1.7958847284317017\n",
      "Epoch: 770, Train Acc: 1.7999130487442017\n",
      "Epoch: 780, Train Acc: 1.7961208820343018\n",
      "Epoch: 790, Train Acc: 1.7931435108184814\n",
      "Epoch: 800, Train Acc: 1.7962151765823364\n",
      "Epoch: 810, Train Acc: 1.798663854598999\n",
      "Epoch: 820, Train Acc: 1.7967032194137573\n",
      "Epoch: 830, Train Acc: 1.7935103178024292\n",
      "Epoch: 840, Train Acc: 1.7998024225234985\n",
      "Epoch: 850, Train Acc: 1.79707670211792\n",
      "Epoch: 860, Train Acc: 1.793908953666687\n",
      "Epoch: 870, Train Acc: 1.794521450996399\n",
      "Epoch: 880, Train Acc: 1.7988691329956055\n",
      "Epoch: 890, Train Acc: 1.8003520965576172\n",
      "Epoch: 900, Train Acc: 1.7981255054473877\n",
      "Epoch: 910, Train Acc: 1.7911503314971924\n",
      "Epoch: 920, Train Acc: 1.7943251132965088\n",
      "Epoch: 930, Train Acc: 1.7990398406982422\n",
      "Epoch: 940, Train Acc: 1.7912507057189941\n",
      "Epoch: 950, Train Acc: 1.8044933080673218\n",
      "Epoch: 960, Train Acc: 1.7982707023620605\n",
      "Epoch: 970, Train Acc: 1.7967000007629395\n",
      "Epoch: 980, Train Acc: 1.791833758354187\n",
      "Epoch: 990, Train Acc: 1.7966281175613403\n",
      "Epoch: 1000, Train Acc: 1.7968111038208008\n",
      "Epoch: 1010, Train Acc: 1.7896157503128052\n",
      "Epoch: 1020, Train Acc: 1.791156530380249\n",
      "Epoch: 1030, Train Acc: 1.7931795120239258\n",
      "Epoch: 1040, Train Acc: 1.7890006303787231\n",
      "Epoch: 1050, Train Acc: 1.7910040616989136\n",
      "Epoch: 1060, Train Acc: 1.7849538326263428\n",
      "Epoch: 1070, Train Acc: 1.7921611070632935\n",
      "Epoch: 1080, Train Acc: 1.790246605873108\n",
      "Epoch: 1090, Train Acc: 1.7890008687973022\n",
      "Epoch: 1100, Train Acc: 1.7883212566375732\n",
      "Epoch: 1110, Train Acc: 1.7869391441345215\n",
      "Epoch: 1120, Train Acc: 1.7897266149520874\n",
      "Epoch: 1130, Train Acc: 1.7894669771194458\n",
      "Epoch: 1140, Train Acc: 1.7917704582214355\n",
      "Epoch: 1150, Train Acc: 1.792722225189209\n",
      "Epoch: 1160, Train Acc: 1.7894983291625977\n",
      "Epoch: 1170, Train Acc: 1.7852281332015991\n",
      "Epoch: 1180, Train Acc: 1.781911849975586\n",
      "Epoch: 1190, Train Acc: 1.7806483507156372\n",
      "Epoch: 1200, Train Acc: 1.7836130857467651\n",
      "Epoch: 1210, Train Acc: 1.7768932580947876\n",
      "Epoch: 1220, Train Acc: 1.7769008874893188\n",
      "Epoch: 1230, Train Acc: 1.7826173305511475\n",
      "Epoch: 1240, Train Acc: 1.7780402898788452\n",
      "Epoch: 1250, Train Acc: 1.7750444412231445\n",
      "Epoch: 1260, Train Acc: 1.777409315109253\n",
      "Epoch: 1270, Train Acc: 1.7855585813522339\n",
      "Epoch: 1280, Train Acc: 1.7758935689926147\n",
      "Epoch: 1290, Train Acc: 1.7785742282867432\n",
      "Epoch: 1300, Train Acc: 1.7795718908309937\n",
      "Epoch: 1310, Train Acc: 1.7796703577041626\n",
      "Epoch: 1320, Train Acc: 1.7739347219467163\n",
      "Epoch: 1330, Train Acc: 1.7783225774765015\n",
      "Epoch: 1340, Train Acc: 1.778704047203064\n",
      "Epoch: 1350, Train Acc: 1.7731947898864746\n",
      "Epoch: 1360, Train Acc: 1.766033411026001\n",
      "Epoch: 1370, Train Acc: 1.7688552141189575\n",
      "Epoch: 1380, Train Acc: 1.7620269060134888\n",
      "Epoch: 1390, Train Acc: 1.767822027206421\n",
      "Epoch: 1400, Train Acc: 1.7634018659591675\n",
      "Epoch: 1410, Train Acc: 1.7606555223464966\n",
      "Epoch: 1420, Train Acc: 1.767307162284851\n",
      "Epoch: 1430, Train Acc: 1.7629485130310059\n",
      "Epoch: 1440, Train Acc: 1.7624399662017822\n",
      "Epoch: 1450, Train Acc: 1.7554290294647217\n",
      "Epoch: 1460, Train Acc: 1.7545892000198364\n",
      "Epoch: 1470, Train Acc: 1.7536332607269287\n",
      "Epoch: 1480, Train Acc: 1.7533717155456543\n",
      "Epoch: 1490, Train Acc: 1.7589845657348633\n",
      "Epoch: 1500, Train Acc: 1.7543058395385742\n",
      "Epoch: 1510, Train Acc: 1.7523363828659058\n",
      "Epoch: 1520, Train Acc: 1.75467848777771\n",
      "Epoch: 1530, Train Acc: 1.7570117712020874\n",
      "Epoch: 1540, Train Acc: 1.7467337846755981\n",
      "Epoch: 1550, Train Acc: 1.7407866716384888\n",
      "Epoch: 1560, Train Acc: 1.7399687767028809\n",
      "Epoch: 1570, Train Acc: 1.7422629594802856\n",
      "Epoch: 1580, Train Acc: 1.7407252788543701\n",
      "Epoch: 1590, Train Acc: 1.7435343265533447\n",
      "Epoch: 1600, Train Acc: 1.7436094284057617\n",
      "Epoch: 1610, Train Acc: 1.7403054237365723\n",
      "Epoch: 1620, Train Acc: 1.7400377988815308\n",
      "Epoch: 1630, Train Acc: 1.7309383153915405\n",
      "Epoch: 1640, Train Acc: 1.7483916282653809\n",
      "Epoch: 1650, Train Acc: 1.7335026264190674\n",
      "Epoch: 1660, Train Acc: 1.7324382066726685\n",
      "Epoch: 1670, Train Acc: 1.7277250289916992\n",
      "Epoch: 1680, Train Acc: 1.7293686866760254\n",
      "Epoch: 1690, Train Acc: 1.720428466796875\n",
      "Epoch: 1700, Train Acc: 1.7334612607955933\n",
      "Epoch: 1710, Train Acc: 1.7219462394714355\n",
      "Epoch: 1720, Train Acc: 1.77156662940979\n",
      "Epoch: 1730, Train Acc: 1.7313013076782227\n",
      "Epoch: 1740, Train Acc: 1.7255083322525024\n",
      "Epoch: 1750, Train Acc: 1.7275700569152832\n",
      "Epoch: 1760, Train Acc: 1.713238000869751\n",
      "Epoch: 1770, Train Acc: 1.7185487747192383\n",
      "Epoch: 1780, Train Acc: 1.7286913394927979\n",
      "Epoch: 1790, Train Acc: 1.7236711978912354\n",
      "Epoch: 1800, Train Acc: 1.7104170322418213\n",
      "Epoch: 1810, Train Acc: 1.705469012260437\n",
      "Epoch: 1820, Train Acc: 1.7116657495498657\n",
      "Epoch: 1830, Train Acc: 1.7072726488113403\n",
      "Epoch: 1840, Train Acc: 1.7098455429077148\n",
      "Epoch: 1850, Train Acc: 1.6964255571365356\n",
      "Epoch: 1860, Train Acc: 1.695379614830017\n",
      "Epoch: 1870, Train Acc: 1.7031171321868896\n",
      "Epoch: 1880, Train Acc: 1.7074204683303833\n",
      "Epoch: 1890, Train Acc: 1.6930944919586182\n",
      "Epoch: 1900, Train Acc: 1.7033395767211914\n",
      "Epoch: 1910, Train Acc: 1.7178176641464233\n",
      "Epoch: 1920, Train Acc: 1.6856244802474976\n",
      "Epoch: 1930, Train Acc: 1.6956017017364502\n",
      "Epoch: 1940, Train Acc: 1.694057583808899\n",
      "Epoch: 1950, Train Acc: 1.6910265684127808\n",
      "Epoch: 1960, Train Acc: 1.6812946796417236\n",
      "Epoch: 1970, Train Acc: 1.7321950197219849\n",
      "Epoch: 1980, Train Acc: 1.6815418004989624\n",
      "Epoch: 1990, Train Acc: 1.677307367324829\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"../data/registers/results/results_500_samples\"\n",
    "batch_size = 64\n",
    "target_index = 4\n",
    "\n",
    "criterion = MeanAbsoluteError()\n",
    "criterion = RMSELoss\n",
    "model = GraphRegressionModel(hidden_dim)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "dataset = CustomGraphDataset(folder_path, target_index=target_index).shuffle()\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "for epoch in range(1, 2000):\n",
    "    train(loader)\n",
    "    train_acc = test(loader)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch:03d}, Train Acc: {train_acc.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.9047],\n",
      "        [5.6694],\n",
      "        [1.9749],\n",
      "        [7.0706],\n",
      "        [4.8222],\n",
      "        [3.7714],\n",
      "        [4.5563],\n",
      "        [4.4475],\n",
      "        [3.2714],\n",
      "        [4.8265],\n",
      "        [4.4475],\n",
      "        [3.5912],\n",
      "        [4.1266],\n",
      "        [4.8065],\n",
      "        [4.4178],\n",
      "        [3.6352],\n",
      "        [6.6901],\n",
      "        [4.1293],\n",
      "        [4.9877],\n",
      "        [4.7674],\n",
      "        [3.6532],\n",
      "        [2.0773],\n",
      "        [4.1749],\n",
      "        [4.0139],\n",
      "        [4.0621],\n",
      "        [3.8844],\n",
      "        [2.8092],\n",
      "        [2.5630],\n",
      "        [4.4777],\n",
      "        [4.2595],\n",
      "        [4.0510],\n",
      "        [4.8137],\n",
      "        [4.2864],\n",
      "        [4.3136],\n",
      "        [4.3001],\n",
      "        [4.5637],\n",
      "        [4.8180],\n",
      "        [4.9416],\n",
      "        [4.7422],\n",
      "        [6.4578],\n",
      "        [3.8132],\n",
      "        [3.5876],\n",
      "        [2.7359],\n",
      "        [4.7502],\n",
      "        [2.4251],\n",
      "        [4.3856],\n",
      "        [4.7969],\n",
      "        [4.3640],\n",
      "        [5.5860],\n",
      "        [4.4913],\n",
      "        [6.8102],\n",
      "        [3.4907],\n",
      "        [3.8190],\n",
      "        [4.3492],\n",
      "        [4.5734],\n",
      "        [3.9967],\n",
      "        [3.6070],\n",
      "        [4.1810],\n",
      "        [4.7994],\n",
      "        [4.4373],\n",
      "        [3.9272],\n",
      "        [4.8824],\n",
      "        [4.2839],\n",
      "        [4.4286]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1.8173, 7.2549, 1.1885, 7.9933, 5.2264, 6.6752, 1.6265, 1.4201, 1.4000,\n",
      "        1.7468, 2.7681, 0.4748, 4.0882, 2.0941, 6.4754, 1.8200, 7.3336, 5.8319,\n",
      "        6.4093, 3.4204, 2.5067, 2.0367, 3.7201, 4.1946, 1.2989, 7.3590, 5.1455,\n",
      "        2.1009, 7.7586, 7.8064, 5.3187, 7.8912, 2.9296, 7.6557, 3.0928, 7.4045,\n",
      "        2.2451, 6.5779, 6.9075, 7.6528, 1.6953, 1.5902, 1.3129, 6.8833, 2.5555,\n",
      "        5.8529, 6.9132, 2.6780, 5.5078, 2.4516, 7.6936, 7.3810, 4.2496, 5.5135,\n",
      "        6.6125, 6.6589, 0.1340, 4.7905, 3.5281, 2.4485, 2.4054, 6.1648, 4.9903,\n",
      "        4.4269])\n",
      "tensor([[4.1169],\n",
      "        [3.6827],\n",
      "        [4.3894],\n",
      "        [3.8716],\n",
      "        [4.2912],\n",
      "        [3.4040],\n",
      "        [4.6492],\n",
      "        [4.0449],\n",
      "        [4.0801],\n",
      "        [5.6953],\n",
      "        [3.7743],\n",
      "        [4.5275],\n",
      "        [3.7255],\n",
      "        [4.8351],\n",
      "        [4.0721],\n",
      "        [4.0580],\n",
      "        [4.3439],\n",
      "        [3.9272],\n",
      "        [1.7427],\n",
      "        [6.9005],\n",
      "        [4.2500],\n",
      "        [3.7289],\n",
      "        [4.1847],\n",
      "        [4.5569],\n",
      "        [4.8848],\n",
      "        [3.8500],\n",
      "        [2.0559],\n",
      "        [3.9229],\n",
      "        [4.2398],\n",
      "        [5.4761],\n",
      "        [3.3647],\n",
      "        [4.1052],\n",
      "        [4.1575],\n",
      "        [4.3994],\n",
      "        [4.4709],\n",
      "        [2.0226],\n",
      "        [4.8701],\n",
      "        [4.7287],\n",
      "        [3.9196],\n",
      "        [4.8065],\n",
      "        [5.8683],\n",
      "        [5.2804],\n",
      "        [5.8587],\n",
      "        [3.6619],\n",
      "        [4.5235],\n",
      "        [3.5703],\n",
      "        [4.0519],\n",
      "        [4.1749],\n",
      "        [1.6493],\n",
      "        [1.9794],\n",
      "        [4.2858],\n",
      "        [3.5336],\n",
      "        [3.4905],\n",
      "        [3.6446],\n",
      "        [4.6602],\n",
      "        [4.8414],\n",
      "        [4.8167],\n",
      "        [4.7047],\n",
      "        [4.6136],\n",
      "        [6.6169],\n",
      "        [4.5085]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1.7406, 1.9538, 6.4751, 2.6431, 2.5697, 4.6176, 1.2836, 4.1345, 6.3632,\n",
      "        7.2181, 2.4014, 1.5926, 2.5893, 6.0604, 7.7357, 3.4395, 6.4948, 2.8404,\n",
      "        1.7618, 6.4409, 2.2708, 2.1424, 6.3944, 6.9987, 7.0286, 2.1560, 1.5746,\n",
      "        7.2984, 1.5886, 4.5283, 2.4809, 4.3282, 4.4100, 5.7635, 4.4125, 1.3604,\n",
      "        7.4456, 0.4703, 4.3122, 2.9929, 4.0821, 2.5638, 7.0548, 3.9295, 1.4809,\n",
      "        1.8678, 6.9916, 5.1927, 1.6779, 3.5313, 2.6025, 5.5657, 2.6369, 2.5336,\n",
      "        7.1889, 3.0217, 6.6143, 3.4242, 3.3893, 6.8146, 4.3920])\n"
     ]
    }
   ],
   "source": [
    "for data in loader:\n",
    "    print(model(data))\n",
    "    print(data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../data/models/v2/final_detuning.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.solver.ml.model import ParametersModel\n",
    "\n",
    "m = ParametersModel(\"../data/models/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParamsPrediction(rise_time=796.688720703125, fall_time=2070.00537109375, omega=8.451778411865234, init_detuning=5.109279155731201, final_detuning=4.145717144012451)\n"
     ]
    }
   ],
   "source": [
    "from src.solver.ml.dataset import matrix_from_file\n",
    "\n",
    "file_path = \"../data/registers/dataset/3_rectangle_3_1_6.json\"\n",
    "\n",
    "adjacency_matrix = matrix_from_file(file_path)\n",
    "\n",
    "prediction = m.predict(adjacency_matrix)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/models/v1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Counter({'101000101': 2905,\n",
       "          '101000100': 165,\n",
       "          '100000101': 157,\n",
       "          '001000101': 155,\n",
       "          '101000001': 142,\n",
       "          '101000010': 133,\n",
       "          '010000101': 132,\n",
       "          '001100001': 123,\n",
       "          '100001100': 108,\n",
       "          '100000001': 73,\n",
       "          '001000100': 72,\n",
       "          '101010101': 65,\n",
       "          '010100001': 38,\n",
       "          '101010000': 38,\n",
       "          '000101000': 36,\n",
       "          '001010001': 34,\n",
       "          '010000010': 34,\n",
       "          '100010100': 34,\n",
       "          '010001100': 28,\n",
       "          '000010101': 26,\n",
       "          '100001010': 26,\n",
       "          '001010101': 25,\n",
       "          '100010101': 25,\n",
       "          '100010001': 24,\n",
       "          '101010100': 23,\n",
       "          '001100010': 21,\n",
       "          '001010100': 20,\n",
       "          '001000001': 17,\n",
       "          '001000010': 17,\n",
       "          '010100010': 17,\n",
       "          '101000000': 17,\n",
       "          '101010001': 16,\n",
       "          '000000101': 15,\n",
       "          '000010100': 15,\n",
       "          '010101000': 14,\n",
       "          '000000001': 13,\n",
       "          '010001010': 13,\n",
       "          '100000010': 11,\n",
       "          '000100001': 10,\n",
       "          '000101010': 10,\n",
       "          '001010000': 10,\n",
       "          '010000100': 10,\n",
       "          '100000100': 10,\n",
       "          '000000100': 9,\n",
       "          '000010001': 9,\n",
       "          '010000001': 9,\n",
       "          '000001000': 8,\n",
       "          '000001100': 8,\n",
       "          '100001000': 8,\n",
       "          '100010000': 8,\n",
       "          '000100000': 6,\n",
       "          '001100000': 6,\n",
       "          '010000000': 5,\n",
       "          '000000010': 4,\n",
       "          '000001010': 4,\n",
       "          '010101010': 4,\n",
       "          '100000000': 4,\n",
       "          '000010000': 3,\n",
       "          '011000101': 3,\n",
       "          '100011100': 3,\n",
       "          '000100010': 2,\n",
       "          '001000000': 2,\n",
       "          '001110001': 2,\n",
       "          '010001000': 2,\n",
       "          '010101100': 2,\n",
       "          '100100001': 2,\n",
       "          '000000000': 1,\n",
       "          '001100101': 1,\n",
       "          '010001101': 1,\n",
       "          '010010101': 1,\n",
       "          '010100011': 1,\n",
       "          '101000110': 1,\n",
       "          '101001100': 1,\n",
       "          '101100001': 1,\n",
       "          '101100010': 1,\n",
       "          '110000101': 1}),\n",
       " ResultScore(total=2.635973473684211, gini_score=0.8381473684210528, sum_score=3.145),\n",
       " ParamsPrediction(rise_time=945.6751708984375, fall_time=2424.459228515625, omega=9.48205852508545, init_detuning=5.073793411254883, final_detuning=4.927931308746338))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.solver.ml.mlqaa import MLQAA\n",
    "\n",
    "\n",
    "MLQAA(\"../data/registers/dataset/9_rectangle_3_3_8.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_PATH = \"../data/registers/results/results_0_samples/\"\n",
    "\n",
    "for file_path in sorted(os.listdir(BASE_PATH), reverse=True):\n",
    "    path = os.path.join(BASE_PATH, file_path)\n",
    "    MLQAA(register_file=path, store_results=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pasqal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
